{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Final 10-K links and Keywords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Chunk of Code Imports Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib2\n",
    "from bs4 import SoupStrainer\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "df = pd.read_csv('health sentiment.csv') #Importing the companies list by industry to get the final link for 10K filing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting HTML links for compaines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df['html'] = 'TBD' #Initializing empty colun html\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "from urllib import FancyURLopener  # This is library that helps us create the headless browser\n",
    "from random import choice #This library helps pick a random item from a list\n",
    "\n",
    "user_agents = [\n",
    "    'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36',\n",
    "    'Opera/9.80 (X11; Linux i686; Ubuntu/14.10) Presto/2.12.388 Version/12.16',\n",
    "    'Mozilla/5.0 (Windows; U; Windows NT 6.1; rv:2.2) Gecko/20110201',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_3) AppleWebKit/537.75.14 (KHTML, like Gecko) Version/7.0.3 Safari/7046A194A',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.135 Safari/537.36 Edge/12.246'\n",
    "]\n",
    "\n",
    "class MyOpener(FancyURLopener, object):\n",
    "    version = choice(user_agents)\n",
    "\n",
    "myopener = MyOpener()\n",
    "\n",
    "page=myopener.open('https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany&company=FOREST+CITY+ENTERPRI&type=10-K&dateb=&owner=exclude&count=100')\n",
    "html = page.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Entire chunks appends html links that will be scrapes for keywords in subsequent sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for j in range(0,len(df)):\n",
    "    myopener = MyOpener()\n",
    "    #print(df['weblink'][j])\n",
    "    page=myopener.open(df['weblink'][j])\n",
    "    html = page.read()\n",
    "    soup = BeautifulSoup(html, 'lxml')  \n",
    "    x = soup.find_all('td')\n",
    "    for i in range(0,len(x)):\n",
    "        #print x[i].get_text()\n",
    "        if(x[i].get_text() == '10-K' and x[i+2].get_text() == '10-K'):\n",
    "           # print j,i\n",
    "            df['html'][j] = 'https://www.sec.gov' + x[i+1].a['href']\n",
    "            break\n",
    "        if(x[i].get_text() == '10-K' and x[i-2].get_text() != '10-K'):\n",
    "           # print j,i\n",
    "            df['html'][j] = 'https://www.sec.gov' + x[i-1].a['href']\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('html_links_fin.csv', sep = ',', header = True, index = False) #Writes files with links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subsequent chunk of code gets the keywords and their frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Inititalizing Keywords\n",
    "keywords = ['analytics', 'big data', 'big-data', 'bitcoin', 'blockchain', 'emerging technologies', 'artificial intelligence', 'neural network', 'cloud', 'data driven', 'storage system', 'cutting edge', 'cutting-edge', 'digital transformation', 'digital innovation', 'digital marketing', 'technological improvement', 'latest technology', 'disruption', 'startup', 'crowdfunding', 'financial technology', 'robotic', 'digital currency', 'natural language', 'cell technology', 'vaccine technology', 'health technology', 'polymer technology', 'drug delivery technology']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Inititalizing the columns for keywords\n",
    "for col in keywords:\n",
    "    df[col] = 'TBD'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "The subsequent chunk finds the keywords in each 10-K and appends it in respective column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for temp in range(0,len(df)):\n",
    "    print temp\n",
    "    myopener = MyOpener()\n",
    "    #print(df['weblink'][j])\n",
    "    page=myopener.open(df['html'][temp])\n",
    "    html = page.read()\n",
    "    for cols in keywords:\n",
    "        df[cols][temp] = len([m.start() for m in re.finditer( cols, html.lower())])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('health sentiment.csv', sep = ',', header = True , index = False) #Writes the file to the industry specific file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
